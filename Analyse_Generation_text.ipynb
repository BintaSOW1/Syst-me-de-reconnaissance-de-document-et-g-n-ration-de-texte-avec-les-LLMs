{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm6Rzw3u-EgK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKD_v7a0zog8"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGpqFeQu0KZa"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbVnOSAN0IEY"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/content/0088-understand-invoices.jpg\")\n",
        "text = pytesseract.image_to_string(image, lang='eng')\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKxYCp9Z0vbX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Exemple : suppression des sauts de lignes inutiles\n",
        "text_clean = re.sub(r'\\n+', '\\n', text)\n",
        "print(text_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ltkOLf505if"
      },
      "outputs": [],
      "source": [
        "# Extraire le numéro de facture\n",
        "match = re.search(r\"Facture\\s*#?\\s*(\\d+)\", text)\n",
        "if match:\n",
        "    numero_facture = match.group(1)\n",
        "\n",
        "# Extraire la date\n",
        "match_date = re.search(r\"(\\d{1,2}/\\d{1,2}/\\d{2,4})\", text)\n",
        "if match_date:\n",
        "    date_facture = match_date.group(1)\n",
        "\n",
        "# Extraire le montant\n",
        "match_montant = re.search(r\"Total\\s*[:\\-]?\\s*(\\d+[\\.,]?\\d*)\\s*€\", text)\n",
        "if match_montant:\n",
        "    montant = match_montant.group(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34cgxJ3I1Dul"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_news_md\")\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOGN8Xzq2Xzr"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1-BZGAdznl6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Charger le modèle anglais de spaCy\n",
        "nlp = spacy.load(\"en_core_web_md\")  # ou \"en_core_web_sm\" si tu veux un modèle plus léger\n",
        "\n",
        "# Exemple de texte issu d'une facture (extrait avec pytesseract par exemple)\n",
        "text = \"\"\"\n",
        "\n",
        "Holi Industrial Estate\n",
        "Hoty\n",
        "Cork\n",
        "République dtlande\n",
        "© trormaions cont\n",
        "(oTOD Media\n",
        "1000 ve fetve\n",
        "Vile, Pays\n",
        "Identiiant du compte 000000\n",
        "‘Apple Distribution InternationalLtd.\n",
        "@ feeture\n",
        "‘Numéro du document :0000000000\n",
        "Date du document: 31 anv. 2023 1:11:15 (UTC)\n",
        "[Ne pas effectuerle paiement\n",
        "\n",
        "\n",
        "\n",
        "Détalis des frais ® @ @ © © © ©\n",
        "© Pande detransacion —Modileda,.TOdeinea,. Nomdslncompaone Tigon Unda Monta des dipenses.. Moan acta (ER)\n",
        "1 atin: 2023-24020. CHL 0000000 Base Anpromeon a * me 00\n",
        "2 ahjna.2028-21amc20.. COTW 0000000 yin Sachets, ategny ow 2370 00\n",
        "2. atin 2022-220. CRTST 0000000 Ander Saar ab fe 5 10 00\n",
        "44 btm 2022-3iom20. CPTE 000000 rider Pod age € 2 ww 00\n",
        "sous um 200\n",
        "watacnrie 20.00% 200\n",
        "rest am 200\n",
        "3) Mode depsioment\n",
        "Umontat de 0 EUR sera delacrte Mastercard se temioant ar 0727\n",
        "@ Uncastrmetomel ae 3774UR« 8 epee atpeses ete capone.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Traitement du texte avec spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Affichage des entités nommées\n",
        "print(\"Extracted Named Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} --> {ent.label_}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gti0ZdaQ7qip"
      },
      "source": [
        "Now, we're going to use EasyOCR package to \"read\" the titles. Modern OCR solutions may still produce a handful of errors, which is why you're encouraged to apply a language model or alternative OCR model to fix possible misspelings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW1NQbeo7rRZ"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    {\n",
        "        \"text\": \"This contract is between ACME Corp and John Doe. Start date: 01/01/2023. End date: 31/12/2023. Role: Data Scientist.\",\n",
        "        \"label\": \"contract\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"Invoice Number: INV-2024-001. Client: John Doe. Amount: $5,000. Date: 15/06/2024.\",\n",
        "        \"label\": \"invoice\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"John Doe is a Machine Learning Engineer with 5 years of experience in Python and TensorFlow.\",\n",
        "        \"label\": \"cv\"\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_2wTwTAgBui"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import joblib\n",
        "\n",
        "# Exemple de données (à étendre dans un vrai cas)\n",
        "data = pd.DataFrame({\n",
        "    \"text\": [\n",
        "        \"Contrat n°5432. M. Jean Dupont. Assurance auto. Début: 01/01/2024. Fin: 31/12/2024.\",\n",
        "        \"Déclaration de sinistre : accident le 03/03/2024 à Bordeaux avec ma Renault Clio.\",\n",
        "        \"Relevé d’information : 2 sinistres survenus en 2022 et 2023. Bonus actuel : 0.85.\",\n",
        "        \"Police n°2345. Assurance habitation. Début: 01/02/2024. Fin: 31/01/2025.\",\n",
        "        \"Accident survenu le 15/05/2024 à Marseille. Véhicule : Citroën C3.\",\n",
        "        \"Historique des sinistres de 2021 à 2023. Bonus-malus : 0.90.\"\n",
        "    ],\n",
        "    \"label\": [\"contrat\", \"sinistre\", \"releve\", \"contrat\", \"sinistre\", \"releve\"]\n",
        "})\n",
        "\n",
        "# Séparation en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], test_size=0.3, random_state=42)\n",
        "\n",
        "# Pipeline\n",
        "pipe = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"rfc\", RandomForestClassifier())\n",
        "])\n",
        "\n",
        "# Entraînement\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Prédiction sur le test\n",
        "y_pred = pipe.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "f1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3Q324Y6iyKn"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn pandas spacy\n",
        "!python -m spacy download en_core_web_md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQF9DBNFim47"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def extract_info(text, doc_type):\n",
        "    doc = nlp(text)\n",
        "    infos = {}\n",
        "\n",
        "    if doc_type == \"sinistre\":\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"DATE\":\n",
        "                infos[\"date_incident\"] = ent.text\n",
        "            elif ent.label_ == \"LOC\":\n",
        "                infos[\"lieu\"] = ent.text\n",
        "        match = re.search(r\"véhicule.*?([A-Z].+)\", text, re.IGNORECASE)\n",
        "        if match:\n",
        "            infos[\"véhicule\"] = match.group(1)\n",
        "\n",
        "    elif doc_type == \"contrat\":\n",
        "        match_debut = re.search(r\"Début\\s*:\\s*(\\d{2}/\\d{2}/\\d{4})\", text)\n",
        "        match_fin = re.search(r\"Fin\\s*:\\s*(\\d{2}/\\d{2}/\\d{4})\", text)\n",
        "        if match_debut:\n",
        "            infos[\"date_debut\"] = match_debut.group(1)\n",
        "        if match_fin:\n",
        "            infos[\"date_fin\"] = match_fin.group(1)\n",
        "\n",
        "    return infos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gRQiYz2tkcG",
        "outputId": "15bfcfe0-c16e-4d9f-f253-eb420e602050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0.post1\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Xhh3z3YVunk1",
        "outputId": "a068534c-ba55-469b-b128-8f54d9a05490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.1\n",
            "    Uninstalling transformers-4.53.1:\n",
            "      Successfully uninstalled transformers-4.53.1\n",
            "Successfully installed transformers-4.53.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6cf9385e9b2c48ddbcedf6ab97332893",
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axb-0gzjsp84"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import torch\n",
        "\n",
        "# 1. Documents à indexer\n",
        "documents = [\n",
        "    \"Contrat n°5432. M. Jean Dupont. Assurance auto. Début: 01/01/2024. Fin: 31/12/2024.\",\n",
        "    \"Déclaration de sinistre : accident le 03/03/2024 à Bordeaux avec ma Renault Clio.\",\n",
        "    \"Relevé d’information : 2 sinistres survenus en 2022 et 2023. Bonus actuel : 0.85.\"\n",
        "]\n",
        "\n",
        "# 2. Embeddings avec sentence-transformers\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "doc_embeddings = embedder.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "# 3. Construction de la base FAISS\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(doc_embeddings.cpu().detach().numpy())\n",
        "\n",
        "# 4. Chargement du tokenizer et modèle Mistral (7B par ex.)\n",
        "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "\n",
        "# Pipeline génération\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "# 5. Fonction recherche + génération\n",
        "def rag_answer(question, top_k=2):\n",
        "    # Encode la question\n",
        "    q_embedding = embedder.encode([question], convert_to_tensor=True).cpu().detach().numpy()\n",
        "\n",
        "    # Recherche des docs les plus proches\n",
        "    D, I = index.search(q_embedding, top_k)\n",
        "    contexts = [documents[i] for i in I[0]]\n",
        "\n",
        "    # Concaténer contexte + question pour le prompt\n",
        "    prompt = \"Contexte : \" + \" \".join(contexts) + \"\\nQuestion : \" + question + \"\\nRéponse :\"\n",
        "\n",
        "    # Génération\n",
        "    outputs = generator(prompt, max_length=200, do_sample=True, temperature=0.7)\n",
        "    return outputs[0]['generated_text']\n",
        "\n",
        "# 6. Test\n",
        "question = \"Quelle est la date de début du contrat de Jean Dupont ?\"\n",
        "print(rag_answer(question))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
